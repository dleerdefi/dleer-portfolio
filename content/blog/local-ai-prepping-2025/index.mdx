---
title: "Local AI Prepping: Build Your Cognitive Bunker"
slug: "local-ai-prepping-2025"
summary: "Run uncensorable AI offline. Hardware guide: RTX 3090 to Mac Studio. Solar power specs. Transform static prepping into adaptive intelligence."
date: "2025-11-03"
updated: "2025-11-03"
tags: ["ai", "preparedness", "local-llm", "self-hosting", "survival", "hardware"]
status: "published"
series: "AI Resilience"
---

The rich are building AI bunkers. Here's how to build yours for $3,000.

The modern prepper stack of food, water and tools is robust but fundamentally static. It's finite, consumable, and can't solve novel problems. A complex medical emergency outside your training. A critical engineering failure. The need to synthesize antibiotics. The static stack fails here.

The tech elite validate the solution: private, subterranean AI data centers. Not naive fortresses—adaptive intelligence systems. [Self-hosted, uncensorable AI](https://blog.mozilla.ai/running-an-open-source-llm-in-2025/) is the cognitive bunker that transforms static survival into dynamic problem-solving.

<Figure
  src="/images/dleer-homelab.webp"
  alt="David Leer's homelab GPU server setup for local AI inference"
  caption="My AI server lives right here on my desk, ready to guide me through the apocalypse."
  width={1920}
  height={1080}
  size="medium"
/>

## The Static Stack Problem

Your freeze-dried food can't teach you surgery. Your water filter can't explain chemical synthesis. Your generator manual assumes you understand electrical engineering.

Traditional prepping optimizes for known threats: power outages, natural disasters, supply disruptions. It fails on the unknown: diseases, complex repairs, social reconstruction.

<Admonition type="warning">
Static knowledge (books, PDFs) requires expertise to even know what to search for. Dynamic reasoning (AI) understands problems in natural language and synthesizes solutions across domains.
</Admonition>

Consider these scenarios:
> "My child has a 103F fever, rigid neck, purple rash. I have antibiotics. Which one? What dosage?"

> "Generator fuel contaminated with water. How do I build a centrifuge and synthesize biodiesel from canola oil?"

A library can't answer these. A [local AI can](https://obrienlabs.medium.com/running-reasoning-llms-like-the-deepseek-r1-70b-43g-locally-for-private-offline-air-gapped-259fa437da8f).

## Why Local AI

Cloud AI requires functioning internet, power grid, and corporate overlords. In crisis, all three fail. Your AI must be:

**Air-gapped**: No internet dependency. [Runs completely offline](https://obrienlabs.medium.com/running-reasoning-llms-like-the-deepseek-r1-70b-43g-locally-for-private-offline-air-gapped-259fa437da8f).

**Private**: Your medical questions, defensive positions, and resources stay secret. No corporate or government logging.

**Uncensorable**: Cloud AI refuses "dangerous" queries. Local AI answers everything: medical synthesis, defensive tactics, radio networks.

The tech elite understand this. Their bunkers aren't just physical—they're cognitive.

## Your Virtual Expert Team

Local AI becomes your always-available specialist team:

- **Doctor**: Diagnose symptoms, guide surgery, calculate drug dosages, veterinary care
- **Engineer**: Repair generators, build water filters, fix inverters, construct shelters
- **Chemist**: Synthesize biodiesel, create antibiotics, purify water, test contamination
- **Agronomist**: Diagnose crop disease, optimize yields, preserve food, raise animals
- **Strategist**: Draft governance frameworks, mediate conflicts, establish trade, write contracts

Local AI will accelerate your existing skills and guide you through complex tasks that you've never attempted.

## Model Selection Guide

Build a portfolio, not a single model. Use [LM Studio](https://lmstudio.ai) or [Ollama](https://ollama.ai) to manage multiple AI models seamlessly:

### General Purpose (The Oracles)
| Model | Parameters | VRAM Needed | Strengths |
| :---- | :---- | :---- | :---- |
| Qwen 2.5 | 72B | 40GB | Math, coding, multilingual |
| Llama 3.3 | 70B | 40GB | Balanced, well-supported |
| Mistral 8x22B | 141B | 80GB | Uncensored, versatile |

### Specialists
| Model | Purpose | VRAM | Notes |
| :---- | :---- | :---- | :---- |
| SurviveV3 | Wilderness survival | 5GB | Emergency procedures |
| UltraMedical | Medical diagnostics | 8GB | Symptoms → treatment |
| Qwen-Coder | Engineering/repair | 20GB | Technical instructions |

<Admonition type="info">
**Key:** "Uncensored" models like Mistral answer questions corporate models refuse. Essential for crisis scenarios.
</Admonition>

## Hardware Tiers

VRAM (video memory) determines model size. More VRAM = smarter AI.

| Tier | Hardware | VRAM | Can Run | Power | Cost | Strategy |
| :---- | :---- | :---- | :---- | :---- | :---- | :---- |
| **Value** | RTX 3090 Used | 24GB | 30B models | 250W | $700 | Best $/VRAM, **upgradable** |
| **Entry** | RTX 4060 Ti | 16GB | 14B models | 150W | $400 | Low power, **upgradable** |
| **Speed** | RTX 5090 | 32GB | 70B models | 350W | $2500 | Fastest, **upgradable** |
| **Genius** | Mac Studio M4 | 128GB | 180B models | 200W | $4000 | Largest models, **fixed** |

<Admonition type="tip">
**Critical difference:** RTX systems scale—add more GPUs as needed. Mac Studio is fixed at purchase.

RTX path: Start with one 3090 ($700), add another for 48GB total ($1400). Mac: Buy once at $4000+, no upgrades possible.

In survival, a slow correct answer beats a fast wrong one. Mac Studio runs massive models others can't—but you're locked into that config forever.
</Admonition>

## Power Requirements Solved

Fear: "Gaming rigs need 1000W!"
Reality: [AI inference is memory-bound, not compute-bound](https://www.pugetsystems.com/labs/articles/tech-primer-what-hardware-do-you-need-to-run-a-local-llm/). Actual power:

- **RTX 4060 Ti**: 150-200W total system
- **RTX 5090 Server**: 350-400W
- **Mac Studio**: 150-200W

Daily energy calculation:
```txt
400W × 24 hours = 9.6 kWh/day
```

This is manageable with commercial solar:

| System | Solar Array | Battery Bank | Days Without Sun | Cost |
| :---- | :---- | :---- | :---- | :---- |
| Mac (200W) | 6.5kW | 10kWh | 2.1 days | $4,500 |
| GPU (400W) | 8.0kW | 20kWh | 2.1 days | $6,500 |

[Server rack solar kits](https://sungoldpower.com/collections/server-rack-solar-kits) are purpose-built for this.

## Implementation Roadmap

### Phase 1: Hardware Selection
- **Tight budget**: Used RTX 3090 ($700) + existing PC
- **Balanced**: RTX 5090 build (~$3500 total)
- **Maximum capability**: Mac Studio M4 Ultra ($6000)

### Phase 2: Download Models Now
While internet works, stockpile models:

1. **Install [LM Studio](https://lmstudio.ai)** (GUI-based, easier for non-technical users)
2. **Download essentials through LM Studio and Hugging Face:**
   - Qwen 2.5 72B (general purpose)
   - Llama 3.3 70B (balanced)
   - Mistral 32B (uncensored)
Models are 20-100GB each. Download now, run forever.

### Phase 3: Power System
- Calculate daily kWh needs
- Size solar array for 2x generation
- Battery bank for 2+ days autonomy
- Pure sine wave inverter (electronics require clean power)

### Phase 4: Testing
Run real scenarios:
- Medical diagnosis from symptoms
- Generator repair from error codes
- Water purification from available chemicals
- Contract drafting for trade agreements

## The Cognitive Advantage

Physical preps help you endure. Cognitive preps help you adapt and rebuild.

When supply chains fail, your AI helps you manufacture. When people get sick, it guides treatment. When conflicts arise, it mediates. When society rebuilds, it provides frameworks.

This isn't science fiction. You can add a super computer to your prepping arsenal today. And it's exactly what the [billionaires are doing](https://medium.com/@adrian.white/ww4-will-be-fought-with-sticks-and-stones-are-you-sure-f1da3a8a8d6a). The democratization is a [gaming PC, some solar panels, and downloaded models](https://www.davidborish.com/post/off-grid-intelligence-building-your-llm-bunker-for-the-digital-apocalypse).

## FAQ

**Won't AI need 1000W of power?**
No. Inference averages 200-400W. A $5K solar kit provides 32kWh/day—enough for the server plus essentials.

**Why not just use cloud AI?**
Grid failure = no access. Plus operational security—your queries about resources, medical needs, and defensive positions stay private.

**Mac vs PC for survival?**
PC (RTX 5090) for speed—fast answers, more queries per day. Mac for intelligence—can run 400B parameter "genius" models that PC can't. Choose based on your priorities.

---

*By David Leer • November 3rd 2025*