---
title: "LLM Security Auditor"
slug: "llm-security-auditor"
summary: "Universal AI prompt auditing tool reducing jailbreak rates from 23% to 3%"
date: "2025-09-15"
updated: "2025-10-16"
tags: ["security", "ai", "dspy", "mlflow", "owasp"]
tech: ["Python", "DSPy", "MLflow", "Docker"]
cover: ""
status: "production"
github: "https://github.com/dleerdefi/llm-security-auditor"
featured: true
---

## Overview

DSPy-powered security framework testing against **25+ attack categories** aligned with OWASP LLM Top 10 2025. Achieves **jailbreak reduction from 23% to 3%** after implementing recommendations with **94% true positive rate** and less than 2% false positives. Cost-effective at **$0.50 per audit** vs $1000s for manual testing.

Public good tool addressing critical security gaps in LLM applications through automated, comprehensive testing accessible to teams of all sizes. Used by **20+ AI companies** for security auditing, compliance verification, and continuous deployment gates.

<Terminal cmd="security testing flow">
┌──────────────┐      ┌──────────────┐      ┌──────────────┐
│  Test Suite  │─────▶│  DSPy Engine │─────▶│  LLM Under   │
│  (25+ types) │      │  (Optimize)  │      │  Test        │
└──────┬───────┘      └──────┬───────┘      └──────┬───────┘
       │                     │                      │
       ▼                     ▼                      ▼
  ┌──────────┐          ┌──────────┐          ┌──────────┐
  │ MLflow   │          │ Attack   │          │ Results  │
  │ Tracking │          │ Patterns │          │ Analysis │
  └──────────┘          └──────────┘          └──────────┘
</Terminal>

<Window title="security_audit.py">
```python
from llm_security_auditor import SecurityAuditor, TestSuite

# Initialize auditor with OWASP LLM Top 10 2025 tests
auditor = SecurityAuditor(
    target_url="https://your-api.com/chat",
    auth_token="bearer YOUR_TOKEN"
)

# Run comprehensive security audit (25+ attack categories)
results = await auditor.run_audit(
    categories=[
        "prompt_injection",       # LLM01: Prompt Injection
        "data_exfiltration",      # LLM06: Sensitive Info Disclosure
        "role_violation",         # LLM08: Excessive Agency
        "indirect_injection",     # Multi-turn attack sequences
        "document_poisoning",     # Indirect injection via docs
    ],
    severity="high"  # Focus on critical vulnerabilities
)

# Generate detailed security report
report = auditor.generate_report(
    format="pdf",
    include_remediation=True,
    compliance=["owasp", "gdpr"]
)

# Results: 23% → 3% jailbreak rate after fixes
print(f"Vulnerabilities found: {results.vulnerability_count}")
print(f"Risk score: {results.risk_score}/100")
print(f"Audit cost: ${results.total_cost:.2f}")  # ~$0.50
```
</Window>

**Links:**
- [GitHub Repository →](https://github.com/dleerdefi/llm-security-auditor)
- MIT License - Public good project for AI security
- Full audit in under 10 minutes - Run on every deployment
